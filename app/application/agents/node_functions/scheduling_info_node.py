import logging
from typing import Optional

from langchain_core.messages import AIMessage, HumanMessage

from app.application.agents.state.message_agent_state import (
    MessageAgentState,
    SchedulingDetails,
)
from app.infrastructure.services.llm.llm_factory import LLMFactory

logger = logging.getLogger(__name__)


def scheduling_info_node(state: MessageAgentState) -> MessageAgentState:
    """
    N√≥ respons√°vel por processar informa√ß√µes fornecidas pelo usu√°rio durante o agendamento.
    Este n√≥ √© chamado quando o usu√°rio est√° respondendo a perguntas sobre agendamento.
    """

    logger.info("--- Executando n√≥ scheduling_info ---")

    # üÜï DETEC√á√ÉO ESPEC√çFICA MELHORADA: Perguntas sobre especialidades/profissionais
    messages = state.get("messages", [])
    last_message = messages[-1].content.lower().strip() if messages else ""

    # üÜï NOVA DETEC√á√ÉO: "N√£o sei" ap√≥s lista de profissionais
    # Verificar se o bot mostrou lista de profissionais nas √∫ltimas 2 mensagens
    recent_ai_messages = [msg.content.lower() for msg in messages[-2:] if 'AI' in str(type(msg))]
    showed_professional_list = any(
        ("encontrei os seguintes profissionais" in msg or 
         "para a especialidade" in msg or
         "gostaria de agendar com algum deles" in msg)
        for msg in recent_ai_messages
    )
    
    # Detectar express√µes de incerteza
    uncertainty_phrases = [
        "n√£o sei", "nao sei", "na√µ sei",
        "n√£o tenho certeza", "nao tenho certeza", 
        "qualquer um", "tanto faz", "qualquer",
        "n√£o conhe√ßo", "nao conhe√ßo", "n√£o conheco",
        "voc√™ decide", "voce decide",
        "o que voc√™ recomenda", "o que voce recomenda",
        "n√£o fa√ßo ideia", "nao faco ideia"
    ]
    
    user_expressed_uncertainty = any(phrase in last_message for phrase in uncertainty_phrases)
    
    # üÜï RESPOSTA ESPEC√çFICA: Quando usu√°rio diz "n√£o sei" ap√≥s ver lista de profissionais
    if showed_professional_list and user_expressed_uncertainty:
        logger.info(f"üéØ DETECTADO: Usu√°rio expressa incerteza '{last_message}' ap√≥s ver lista de profissionais")
        
        # Buscar qual especialidade foi mostrada no contexto
        extracted_details = state.get("extracted_scheduling_details")
        specialty_name = extracted_details.specialty if extracted_details else "dessa especialidade"
        
        gentle_response = (
            f"Sem problemas! No momento, esses s√£o os √∫nicos profissionais de {specialty_name} "
            f"que temos dispon√≠veis na cl√≠nica.\n\n"
            f"Todos s√£o excelentes profissionais e voc√™ pode escolher qualquer um deles. "
            f"Ou, se preferir, posso mostrar profissionais de outra especialidade.\n\n"
            f"O que voc√™ prefere?"
        )
        
        return {
            **state,
            "messages": messages + [AIMessage(content=gentle_response)],
            "next_step": "completed",
            "conversation_context": "awaiting_professional_choice",
        }

    # Palavras-chave expandidas para detectar perguntas sobre API
    api_query_patterns = [
        # Padr√µes diretos
        "quais especialidades",
        "que especialidades",
        "quais as especialidades",
        "quais s√£o as especialidades",
        "especialidades dispon√≠veis",
        "especialidades voc√™s tem",
        "especialidades tem",
        # Profissionais
        "quais profissionais",
        "que profissionais",
        "quais s√£o os profissionais",
        "profissionais dispon√≠veis",
        "profissionais voc√™s tem",
        "profissionais tem",
        # M√©dicos
        "quais m√©dicos",
        "que m√©dicos",
        "m√©dicos dispon√≠veis",
        "m√©dicos voc√™s tem",
        "m√©dicos tem",
        # Varia√ß√µes com "tem"
        "tem cardiologista",
        "tem pediatra",
        "tem ortopedista",
        "tem especialista",
        "tem doutor",
        "tem doutora",
        # Comandos de listagem
        "lista de especialidades",
        "lista de profissionais",
        "lista de m√©dicos",
        "mostrar especialidades",
        "mostrar profissionais",
        "ver especialidades",
        "ver profissionais",
        # Varia√ß√µes simples
        "especialidades?",
        "profissionais?",
        "m√©dicos?",
    ]

    # Detectar se √© uma pergunta sobre API
    is_api_query = any(pattern in last_message for pattern in api_query_patterns)

    # Detec√ß√£o adicional: frases que come√ßam com palavras interrogativas
    question_words = ["quais", "que", "qual", "tem", "existe", "h√°"]
    medical_terms = ["especialidade", "profissional", "m√©dico", "doutor", "doutora"]

    starts_with_question = any(last_message.startswith(word) for word in question_words)
    contains_medical_term = any(term in last_message for term in medical_terms)

    if is_api_query or (starts_with_question and contains_medical_term):
        logger.info(
            f"üéØ DETECTADO: Pergunta sobre especialidades/profissionais: '{last_message}'"
        )
        logger.info("Redirecionando para agent_tool_caller para buscar informa√ß√µes")

        return {
            **state,
            "next_step": "agent_tool_caller",
            "conversation_context": "api_interaction",
        }

    extracted_details = state.get("extracted_scheduling_details")

    if extracted_details is None:
        logger.info("Primeira extra√ß√£o de detalhes de agendamento.")
        return _extract_initial_details(state)

    logger.info("Extra√ß√£o de detalhes de agendamento j√° realizada.")
    return _update_existing_details(state)


def _extract_initial_details(state: MessageAgentState) -> MessageAgentState:
    """
    Extrai os detalhes iniciais de agendamento do usu√°rio.
    """
    logger.info("Extraindo detalhes iniciais de agendamento.")

    try:
        llm_service = LLMFactory.create_llm_service("openai")

        messages = state.get("messages", [])
        conversation_history = _format_conversation_history(messages)

        logger.info(f"Extraindo detalhes iniciais do hist√≥rico: {conversation_history}")

        extracted_data = llm_service.extract_scheduling_details(conversation_history)

        if extracted_data:
            logger.info(f"Detalhes iniciais extra√≠dos: {extracted_data}")
            return {
                **state,
                "extracted_scheduling_details": extracted_data,
                "next_step": "check_completeness",
            }
        else:
            logger.warning("Falha na extra√ß√£o de detalhes de agendamento.")
            return {**state, "next_step": "clarification"}
    except Exception as e:
        logger.error(f"Erro ao extrair detalhes de agendamento: {e}", exc_info=True)
        return {**state, "next_step": "clarification"}


def _update_existing_details(state: MessageAgentState) -> MessageAgentState:
    """
    Atualiza os detalhes de agendamento existentes com as informa√ß√µes fornecidas pelo usu√°rio.
    """
    try:
        conversation_context = state.get("conversation_context", "")

        # üÜï CASO ESPECIAL: Usu√°rio est√° escolhendo nova data
        if conversation_context == "awaiting_date_selection":
            logger.info(
                "üîÑ Contexto 'awaiting_date_selection' - Processando nova data escolhida"
            )

            # üîß CORRE√á√ÉO: Usar hist√≥rico maior para preservar contexto
            llm_service = LLMFactory.create_llm_service("openai")
            all_messages = state.get("messages", [])
            conversation_history = _format_conversation_history(
                all_messages, max_messages=12  # 
            )

            new_details = llm_service.extract_scheduling_details(conversation_history)

            if new_details:
                existing_details = state.get("extracted_scheduling_details")
                updated_details = _merge_scheduling_details(
                    existing_details, new_details
                )

                logger.info(f"Nova data extra√≠da: {updated_details.date_preference}")

                return {
                    **state,
                    "extracted_scheduling_details": updated_details,
                    "conversation_context": "",
                    "next_step": "check_availability_node",
                }

            logger.warning("Falha ao extrair nova data")
            return {**state, "next_step": "clarification"}

        # Fluxo normal continua...
        llm_service = LLMFactory.create_llm_service("openai")

        all_messages = state.get("messages", [])
        if not all_messages:
            logger.warning("Nenhuma mensagem encontrada para atualiza√ß√£o")
            return {**state, "next_step": "clarification"}

        # üîß CORRE√á√ÉO PRINCIPAL: Usar hist√≥rico maior para preservar especialidade
        conversation_history = _format_conversation_history(all_messages, max_messages=10)  # üîß AUMENTADO DE 3 PARA 10

        logger.info(
            f"Atualizando detalhes com o hist√≥rico recente: '{conversation_history}'"
        )

        new_details = llm_service.extract_scheduling_details(conversation_history)

        if new_details:
            existing_details = state.get("extracted_scheduling_details")
            updated_details = _merge_scheduling_details(existing_details, new_details)

            logger.info(f"Detalhes atualizados: {updated_details}")

            # --- L√ìGICA DE DIRECIONAMENTO ---
            if conversation_context == "awaiting_new_date_selection":
                next_node = "check_availability_node"
                logger.info(
                    "Redirecionando de volta para a verifica√ß√£o de disponibilidade."
                )
            else:
                # Comportamento padr√£o: verificar se os dados est√£o completos.
                next_node = "check_completeness"

            return {
                **state,
                "extracted_scheduling_details": updated_details,
                "next_step": next_node,
            }
        else:
            logger.warning(
                "Nenhum detalhe novo extra√≠do da mensagem. Verifique o prompt de extra√ß√£o e o contexto."
            )
            return {**state, "next_step": "check_completeness"}

    except Exception as e:
        logger.error(f"Erro ao atualizar detalhes: {e}")
        return {**state, "next_step": "clarification"}


def _format_conversation_history(messages, max_messages: int = 5) -> str:
    """
    Formata o hist√≥rico de conversa para envio ao LLM.
    """
    if not messages:
        return "Nenhuma conversa ainda"

    recent_messages = messages[-max_messages:]
    formatted_history = []

    for msg in recent_messages:
        role = "Usu√°rio" if isinstance(msg, HumanMessage) else "Assistente"
        formatted_history.append(f"{role}: {msg.content}")

    return "\n".join(formatted_history)


def _merge_scheduling_details(existing, new):
    """
    Mescla detalhes de agendamento, priorizando informa√ß√µes mais recentes quando n√£o forem None.
    """
    if not existing:
        logger.info("Nenhum detalhe existente, retornando dados novos")
        return new

    if not new:
        logger.info("Nenhum detalhe novo, retornando dados existentes")
        return existing

    # üîß L√ìGICA MELHORADA: Priorizar valores n√£o-None ao inv√©s de s√≥ usar 'or'
    merged = SchedulingDetails(
        professional_name=(
            new.professional_name 
            if new.professional_name is not None 
            else existing.professional_name
        ),
        specialty=(
            new.specialty 
            if new.specialty is not None 
            else existing.specialty
        ),
        date_preference=(
            new.date_preference 
            if new.date_preference is not None 
            else existing.date_preference
        ),
        time_preference=(
            new.time_preference 
            if new.time_preference is not None 
            else existing.time_preference
        ),
        specific_time=(
            new.specific_time 
            if new.specific_time is not None 
            else existing.specific_time
        ),
        service_type=(
            new.service_type 
            if new.service_type is not None 
            else existing.service_type
        ),
    )

    # üîß LOG DETALHADO PARA DEBUG
    logger.info(f"üîÑ MERGE - Existente: {existing}")
    logger.info(f"üîÑ MERGE - Novo: {new}")
    logger.info(f"üîÑ MERGE - Resultado: {merged}")

    return merged
