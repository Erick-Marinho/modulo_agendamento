import logging
from typing import Optional

from langchain_core.messages import AIMessage, HumanMessage

from app.application.agents.state.message_agent_state import (
    MessageAgentState,
    SchedulingDetails,
)
from app.infrastructure.services.llm.llm_factory import LLMFactory

logger = logging.getLogger(__name__)


def scheduling_info_node(state: MessageAgentState) -> MessageAgentState:
    """
    N√≥ respons√°vel por processar informa√ß√µes fornecidas pelo usu√°rio durante o agendamento.
    Este n√≥ √© chamado quando o usu√°rio est√° respondendo a perguntas sobre agendamento.
    """

    logger.info("--- Executando n√≥ scheduling_info ---")

    # üÜï DETEC√á√ÉO ESPEC√çFICA MELHORADA: Perguntas sobre especialidades/profissionais
    messages = state.get("messages", [])
    last_message = messages[-1].content.lower().strip() if messages else ""

    # Palavras-chave expandidas para detectar perguntas sobre API
    api_query_patterns = [
        # Padr√µes diretos
        "quais especialidades",
        "que especialidades",
        "quais as especialidades",
        "quais s√£o as especialidades",
        "especialidades dispon√≠veis",
        "especialidades voc√™s tem",
        "especialidades tem",
        # Profissionais
        "quais profissionais",
        "que profissionais",
        "quais s√£o os profissionais",
        "profissionais dispon√≠veis",
        "profissionais voc√™s tem",
        "profissionais tem",
        # M√©dicos
        "quais m√©dicos",
        "que m√©dicos",
        "m√©dicos dispon√≠veis",
        "m√©dicos voc√™s tem",
        "m√©dicos tem",
        # Varia√ß√µes com "tem"
        "tem cardiologista",
        "tem pediatra",
        "tem ortopedista",
        "tem especialista",
        "tem doutor",
        "tem doutora",
        # Comandos de listagem
        "lista de especialidades",
        "lista de profissionais",
        "lista de m√©dicos",
        "mostrar especialidades",
        "mostrar profissionais",
        "ver especialidades",
        "ver profissionais",
        # Varia√ß√µes simples
        "especialidades?",
        "profissionais?",
        "m√©dicos?",
    ]

    # Detectar se √© uma pergunta sobre API
    is_api_query = any(pattern in last_message for pattern in api_query_patterns)

    # Detec√ß√£o adicional: frases que come√ßam com palavras interrogativas
    question_words = ["quais", "que", "qual", "tem", "existe", "h√°"]
    medical_terms = ["especialidade", "profissional", "m√©dico", "doutor", "doutora"]

    starts_with_question = any(last_message.startswith(word) for word in question_words)
    contains_medical_term = any(term in last_message for term in medical_terms)

    if is_api_query or (starts_with_question and contains_medical_term):
        logger.info(
            f"üéØ DETECTADO: Pergunta sobre especialidades/profissionais: '{last_message}'"
        )
        logger.info("Redirecionando para agent_tool_caller para buscar informa√ß√µes")

        return {
            **state,
            "next_step": "agent_tool_caller",
            "conversation_context": "api_interaction",
        }

    extracted_details = state.get("extracted_scheduling_details")

    if extracted_details is None:
        logger.info("Primeira extra√ß√£o de detalhes de agendamento.")
        return _extract_initial_details(state)

    logger.info("Extra√ß√£o de detalhes de agendamento j√° realizada.")
    return _update_existing_details(state)


def _extract_initial_details(state: MessageAgentState) -> MessageAgentState:
    """
    Extrai os detalhes iniciais de agendamento do usu√°rio.
    """
    logger.info("Extraindo detalhes iniciais de agendamento.")

    try:
        llm_service = LLMFactory.create_llm_service("openai")

        messages = state.get("messages", [])
        conversation_history = _format_conversation_history(messages)

        logger.info(f"Extraindo detalhes iniciais do hist√≥rico: {conversation_history}")

        extracted_data = llm_service.extract_scheduling_details(conversation_history)

        if extracted_data:
            logger.info(f"Detalhes iniciais extra√≠dos: {extracted_data}")
            return {
                **state,
                "extracted_scheduling_details": extracted_data,
                "next_step": "check_completeness",
            }
        else:
            logger.warning("Falha na extra√ß√£o de detalhes de agendamento.")
            return {**state, "next_step": "clarification"}
    except Exception as e:
        logger.error(f"Erro ao extrair detalhes de agendamento: {e}", exc_info=True)
        return {**state, "next_step": "clarification"}


def _update_existing_details(state: MessageAgentState) -> MessageAgentState:
    """
    Atualiza os detalhes de agendamento existentes com as informa√ß√µes fornecidas pelo usu√°rio.
    """
    try:
        conversation_context = state.get("conversation_context", "")

        # üÜï CASO ESPECIAL: Usu√°rio est√° escolhendo nova data
        if conversation_context == "awaiting_date_selection":
            logger.info(
                "üîÑ Contexto 'awaiting_date_selection' - Processando nova data escolhida"
            )

            # Apenas extrair e atualizar os detalhes - N√ÉO gerar mensagem
            llm_service = LLMFactory.create_llm_service("openai")
            all_messages = state.get("messages", [])
            conversation_history = _format_conversation_history(
                all_messages, max_messages=3
            )

            new_details = llm_service.extract_scheduling_details(conversation_history)

            if new_details:
                existing_details = state.get("extracted_scheduling_details")
                updated_details = _merge_scheduling_details(
                    existing_details, new_details
                )

                logger.info(f"Nova data extra√≠da: {updated_details.date_preference}")

                return {
                    **state,
                    "extracted_scheduling_details": updated_details,
                    "conversation_context": "",  # Limpar contexto
                    "next_step": "check_availability_node",
                }

            logger.warning("Falha ao extrair nova data")
            return {**state, "next_step": "clarification"}

        # Fluxo normal continua...
        llm_service = LLMFactory.create_llm_service("openai")

        all_messages = state.get("messages", [])
        if not all_messages:
            logger.warning("Nenhuma mensagem encontrada para atualiza√ß√£o")
            return {**state, "next_step": "clarification"}

        conversation_history = _format_conversation_history(all_messages, max_messages=3)

        logger.info(
            f"Atualizando detalhes com o hist√≥rico recente: '{conversation_history}'"
        )

        new_details = llm_service.extract_scheduling_details(conversation_history)

        if new_details:
            existing_details = state.get("extracted_scheduling_details")
            updated_details = _merge_scheduling_details(existing_details, new_details)

            logger.info(f"Detalhes atualizados: {updated_details}")

            # --- L√ìGICA DE DIRECIONAMENTO ---
            if conversation_context == "awaiting_new_date_selection":
                next_node = "check_availability_node"
                logger.info(
                    "Redirecionando de volta para a verifica√ß√£o de disponibilidade."
                )
            else:
                # Comportamento padr√£o: verificar se os dados est√£o completos.
                next_node = "check_completeness"

            return {
                **state,
                "extracted_scheduling_details": updated_details,
                "next_step": next_node,
            }
        else:
            logger.warning(
                "Nenhum detalhe novo extra√≠do da mensagem. Verifique o prompt de extra√ß√£o e o contexto."
            )
            return {**state, "next_step": "check_completeness"}

    except Exception as e:
        logger.error(f"Erro ao atualizar detalhes: {e}")
        return {**state, "next_step": "clarification"}


def _format_conversation_history(messages, max_messages: int = 5) -> str:
    """
    Formata o hist√≥rico de conversa para envio ao LLM.
    """
    if not messages:
        return "Nenhuma conversa ainda"

    recent_messages = messages[-max_messages:]
    formatted_history = []

    for msg in recent_messages:
        role = "Usu√°rio" if isinstance(msg, HumanMessage) else "Assistente"
        formatted_history.append(f"{role}: {msg.content}")

    return "\n".join(formatted_history)


def _merge_scheduling_details(existing, new):
    """
    Mescla detalhes de agendamento, priorizando informa√ß√µes mais recentes.
    """
    if not existing:
        logger.info("Nenhum detalhe existente, retornando dados novos")
        return new

    if not new:
        logger.info("Nenhum detalhe novo, retornando dados existentes")
        return existing

    merged = SchedulingDetails(
        professional_name=existing.professional_name or new.professional_name,
        specialty=existing.specialty or new.specialty,
        date_preference=existing.date_preference or new.date_preference,
        time_preference=existing.time_preference or new.time_preference,
        service_type=existing.service_type or new.service_type,
    )

    return merged
