import logging

from app.application.agents.state.message_agent_state import MessageAgentState
from app.infrastructure.services.llm.llm_factory import LLMFactory
from langchain_core.messages import HumanMessage
from app.domain.sheduling_details import SchedulingDetails
from langchain_core.messages import BaseMessage

logger = logging.getLogger(__name__)

AGENT_TOOL_CALLER_NODE_NAME = "agent_tool_caller"


def orquestrator_node(state: MessageAgentState) -> MessageAgentState:
    """
    N√≥ orquestrador que classifica a inten√ß√£o do usu√°rio e define o pr√≥ximo passo.
    """
    logger.info(f"--- Executando n√≥ orquestrador ---")

    messages = state.get("messages", [])
    conversation_history_str = _format_conversation_history_for_prompt(
        messages
    )

    existing_details = state.get("extracted_scheduling_details")

    llm_service = LLMFactory.create_llm_service("openai")
    new_details = llm_service.extract_scheduling_details(
        conversation_history_str
    )

    updated_details = _merge_scheduling_details(existing_details, new_details)

    # Atualiza o estado imediatamente
    state["extracted_scheduling_details"] = updated_details
    logger.info(f"Orquestrador atualizou os detalhes: {updated_details}")

    # PRIMEIRA PRIORIDADE: Detectar men√ß√£o de especialidade e ser proativo
    last_message = messages[-1].content.lower().strip() if messages else ""

    # Lista expandida de especialidades e suas varia√ß√µes
    specialty_keywords = [
        "cardiologia",
        "cardiologista",
        "cardio",
        "pediatria",
        "pediatra",
        "pedra",
        "ortopedia",
        "ortopedista",
        "orto",
        "cl√≠nico geral",
        "clinico geral",
        "cl√≠nico",
        "clinico",
        "ginecologia",
        "ginecologista",
        "gineco",
        "dermatologia",
        "dermatologista",
        "dermato",
        "neurologia",
        "neurologista",
        "neuro",
        "psiquiatria",
        "psiquiatra",
    ]

    # Se o usu√°rio mencionou uma especialidade E o sistema extraiu uma especialidade, ser proativo
    if (
        updated_details
        and updated_details.specialty
        and not updated_details.professional_name
        and any(keyword in last_message for keyword in specialty_keywords)
    ):
        logger.info(
            f"üéØ DETECTADO: Usu√°rio mencionou especialidade '{last_message}' -> Extra√≠do: '{updated_details.specialty}'. Sendo proativo!"
        )
        return {
            **state,
            "next_step": AGENT_TOOL_CALLER_NODE_NAME,
            "conversation_context": "specialty_selection",
        }

    # SEGUNDA PRIORIDADE: Verificar disponibilidade
    if any(
        keyword in last_message
        for keyword in [
            "dispon√≠vel",
            "datas",
            "hor√°rios",
            "agenda",
            "disponibilidade",
            "livre",
            "vago",
            "quando",
        ]
    ):
        if updated_details and updated_details.professional_name:
            logger.info(
                f"Usu√°rio perguntou sobre disponibilidade para '{updated_details.professional_name}'. Direcionando para tool."
            )
            return {
                **state,
                "next_step": AGENT_TOOL_CALLER_NODE_NAME,
                "conversation_context": "checking_availability",
            }
        else:
            logger.info(
                "Usu√°rio perguntou sobre disponibilidade mas n√£o definiu profissional. Direcionando para esclarecimento."
            )
            return {
                **state,
                "next_step": "clarification",
                "missing_fields": ["nome do profissional"],
            }

    # TERCEIRA PRIORIDADE: Calcular campos faltantes apenas se n√£o detectou especialidade
    calculated_missing_fields = []
    if updated_details:
        if (
            not updated_details.professional_name
            and not updated_details.specialty
        ):
            calculated_missing_fields.append(
                "nome do profissional ou especialidade"
            )
        elif (
            not updated_details.professional_name and updated_details.specialty
        ):
            # Se tem especialidade mas n√£o tem profissional, N√ÉO adiciona aos campos faltantes
            # porque vamos buscar os profissionais automaticamente
            pass
        if not updated_details.date_preference:
            calculated_missing_fields.append("data de prefer√™ncia")
        if not updated_details.time_preference:
            calculated_missing_fields.append("turno de prefer√™ncia")
        if not updated_details.service_type:
            calculated_missing_fields.append("tipo de servi√ßo")

    # Se extraiu informa√ß√µes de agendamento e faltam campos cr√≠ticos, vai para clarification
    if (
        updated_details
        and updated_details.service_type
        and calculated_missing_fields
    ):
        logger.info(
            f"Agendamento detectado com campos faltando: {calculated_missing_fields}. Direcionando para clarification."
        )
        return {
            **state,
            "missing_fields": calculated_missing_fields,
            "next_step": "clarification",
            "conversation_context": "scheduling_flow",
        }

    current_next_step = state.get("next_step", "")
    if current_next_step == "awaiting_final_confirmation":
        logger.info("Estado indica que estamos aguardando confirma√ß√£o final")
        return {**state, "next_step": "final_confirmation"}

    if current_next_step == "awaiting_correction":
        logger.info(
            "Estado indica que estamos aguardando corre√ß√£o - direcionando para scheduling_info"
        )
        return {
            **state,
            "next_step": "scheduling_info",
            "conversation_context": "correcting_data",
        }

    conversation_context = state.get("conversation_context")

    # Se o usu√°rio est√° selecionando um HOR√ÅRIO, v√° para o agendamento final.
    if conversation_context == "awaiting_slot_selection":
        logger.info(
            f"Contexto √© '{conversation_context}', direcionando para o agendamento final."
        )
        return {**state, "next_step": "book_appointment_node"}

    # Se o usu√°rio est√° selecionando uma nova DATA, volte para a coleta de informa√ß√µes.
    if conversation_context == "awaiting_new_date_selection":
        logger.info(
            f"Contexto √© '{conversation_context}', direcionando para a coleta de informa√ß√µes (scheduling_info)."
        )
        return {**state, "next_step": "scheduling_info"}

    # NOVA L√ìGICA: Verificar se estamos no meio de um fluxo de agendamento
    missing_fields = state.get("missing_fields", [])

    # CORRIGIDO: usar updated_details em vez de extracted_details
    if updated_details and missing_fields:
        logger.info(
            f"Contexto de agendamento detectado com campos faltando: {missing_fields}. "
            "Tratando resposta como scheduling_info."
        )
        return {
            **state,
            "next_step": "scheduling_info",
            "conversation_context": "scheduling_flow",
        }

    last_human_message_content = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_human_message_content = msg.content
            break

    if not last_human_message_content:
        logger.warning(
            "Nenhuma mensagem humana encontrada no estado para o orquestrador."
        )
        if state.get("message"):
            last_human_message_content = state.get("message")
        else:
            logger.warning(
                "Orquestrador: Nenhuma mensagem humana para classificar."
            )
            return {
                **state,
                "next_step": "unclear",
                "conversation_context": "system_error",
            }

    logger.info(
        f"Orquestrador classificando mensagem: '{last_human_message_content}'"
    )

    try:
        llm_service = LLMFactory.create_llm_service("openai")
        classification = llm_service.classify_message(
            last_human_message_content
        )

        classification = classification.strip().lower()
        logger.info(
            f"Classifica√ß√£o retornada pelo LLM para orquestrador: '{classification}'"
        )

        valid_classifications = [
            "scheduling",
            "scheduling_info",
            "greeting",
            "farewell",
            "api_query",
            "specialty_selection",
            "other",
            "unclear",
        ]

        if classification not in valid_classifications:
            logger.warning(
                f"Classifica√ß√£o inv√°lida do LLM: '{classification}'. Usando 'unclear' como fallback."
            )
            classification = "unclear"

        next_step_map = {
            "scheduling": "scheduling",
            "scheduling_info": "scheduling_info",
            "greeting": "greeting",
            "farewell": "farewell",
            "api_query": AGENT_TOOL_CALLER_NODE_NAME,
            "specialty_selection": AGENT_TOOL_CALLER_NODE_NAME,
            "other": "other",
            "unclear": "fallback_node",
        }

        next_node = next_step_map.get(classification, "fallback_node")

        new_conversation_context = classification
        if classification in ["scheduling", "scheduling_info"]:
            new_conversation_context = "scheduling_flow"
        elif classification in ["api_query", "specialty_selection"]:
            new_conversation_context = "api_interaction"

        logger.info(
            f"Orquestrador definiu next_step para: '{next_node}' com contexto: '{new_conversation_context}'"
        )
        return {
            **state,
            "next_step": next_node,
            "conversation_context": new_conversation_context,
        }

    except Exception as e:
        logger.error(
            f"Erro ao classificar mensagem no orquestrador: {e}", exc_info=True
        )
        return {
            **state,
            "next_step": "fallback_node",
            "conversation_context": "system_error",
        }


def _format_conversation_history_for_prompt(
    messages: list[BaseMessage], max_messages: int = 10
) -> str:
    if not messages:
        return "Nenhuma conversa ainda"
    recent_messages = messages[-max_messages:]
    formatted_history = []
    for msg in recent_messages:
        role = "Usu√°rio" if isinstance(msg, HumanMessage) else "Assistente"
        formatted_history.append(f"{role}: {msg.content}")
    return "\n".join(formatted_history)


def _merge_scheduling_details(
    existing: SchedulingDetails, new: SchedulingDetails
) -> SchedulingDetails:
    if not existing:
        return new
    if not new:
        return existing

    # L√≥gica de mesclagem: O novo valor (extra√≠do da conversa mais recente) tem prioridade.
    merged = SchedulingDetails(
        professional_name=new.professional_name or existing.professional_name,
        specialty=new.specialty or existing.specialty,
        date_preference=new.date_preference or existing.date_preference,
        time_preference=new.time_preference or existing.time_preference,
        service_type=new.service_type or existing.service_type,
    )
    return merged
